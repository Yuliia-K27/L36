{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80327ff7-ab6a-428e-9fd9-69f63d904409",
   "metadata": {},
   "source": [
    "1.Провести крос-валідацію для моделі, побудованої на основі датафрейму student_scores з попереднього завдання.\n",
    "Обгрунтувати обраний метод крос-валідації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5359ab66-676a-4e6c-b760-19d7a44b555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92 (+/- 0.14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Завантаження даних з csv-файлу\n",
    "data = pd.read_csv('student_scores.csv')\n",
    "\n",
    "# Розділення на ознаки та цільову змінну\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "# Побудова моделі лінійної регресії\n",
    "model = LinearRegression()\n",
    "\n",
    "# Проведення крос-валідації\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# Виведення результатів крос-валідації\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f1bc4-a8b7-4553-b210-00257e776929",
   "metadata": {},
   "source": [
    "У цьому коді ми завантажуємо дані з csv-файлу, розділяємо їх на ознаки та цільову змінну, побудовуємо модель лінійної регресії та застосовуємо крос-валідацію з параметром cv=5 для розбиття набору даних на 5 піднаборів. \n",
    "Результати крос-валідації виводяться на екран у вигляді середнього значення точності та стандартного відхилення."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a71ce6-5cf6-4173-8969-3eeca3e27a9e",
   "metadata": {},
   "source": [
    "2: Провести крос-валідацію для моделі, побудованої на основі датафрейму petrol_consumption з попереднього завдання.\n",
    "Обгрунтувати обраний метод крос-валідації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b1d7d0-8cfd-4ce8-b199-f6936c8a4060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -0.18 (+/- 1.32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Завантаження даних з csv-файлу\n",
    "data = pd.read_csv('petrol_consumption.csv')\n",
    "\n",
    "# Розділення на ознаки та цільову змінну\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Побудова моделі лінійної регресії\n",
    "model = LinearRegression()\n",
    "\n",
    "# Проведення крос-валідації\n",
    "scores = cross_val_score(model, X, y, cv=10)\n",
    "\n",
    "# Виведення результатів крос-валідації\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed472a8-19c3-4a48-8330-463054d72c41",
   "metadata": {},
   "source": [
    "Обраний метод крос-валідації - це \"згорткова крос-валідація\" (k-fold cross-validation), де набір даних розбивається на k піднаборів.\n",
    "Модель навчається на k-1 піднаборах та оцінюється на залишковому піднаборі, і ця процедура повторюється k разів для кожного з k піднаборів. Кожна ітерація надає результат оцінки моделі, і фінальний результат є середньою точністю всіх ітерацій. Крос-валідація дозволяє оцінити ефективність моделі та зменшити ризик перенавчання, тому є важливим етапом в розробці будь-якої моделі машинного навчання."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79077267-39a1-4dd8-baaa-fc9f7974b268",
   "metadata": {},
   "source": [
    "У першому завданні ми застосували метод \"перехресної перевірки з вилученням одного об'єкта\" (Leave-One-Out Cross-Validation, LOOCV). Цей метод має наступні переваги:\n",
    "\n",
    "Використовується для дуже малих наборів даних, коли кількість об'єктів набагато менше, ніж кількість ознак. LOOCV дає можливість використовувати максимально можливу кількість даних для тренування моделі, при цьому забезпечуючи об'єктивну оцінку її точності.\n",
    "Метод є повністю безперебійним, тому що кожен об'єкт використовується як тестовий набір, що дозволяє отримати максимально точну оцінку ефективності моделі.\n",
    "LOOCV дозволяє зменшити випадкову варіацію результатів, оскільки використовується максимальна кількість даних для навчання моделі.\n",
    "Проте LOOCV також має свої недоліки:\n",
    "\n",
    "Метод може бути дуже часоємним для великих наборів даних, оскільки кількість ітерацій дорівнює кількості об'єктів у наборі даних.\n",
    "LOOCV може бути досить чутливим до випадкових відхилень в даних, оскільки виключення одного об'єкта може привести до значних змін у межах точності моделі."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0455b-88ff-489c-83a9-687efed471c1",
   "metadata": {},
   "source": [
    "У другому завданні ми застосували метод \"згорткової крос-валідації\" (k-fold cross-validation). Цей метод має наступні переваги:\n",
    "\n",
    "Метод є ефективним для великих наборів даних, коли LOOCV може бути занадто часоємним.\n",
    "K-fold cross-validation дозволяє використовувати кожен об'єкт як частину тренування та як частину тестування, що дозволяє більш об'єктивно оцінювати точність моделі.\n",
    "\n",
    "Метод дає можливість отримати середнє значення точності моделі на різних комбінаціях тренувальних та тестових наборів даних, що дозволяє зменшити вплив випадкових відхилень в даних та забезпечити більш об'єктивну оцінку ефективності моделі.\n",
    "Крім того, k-fold cross-validation є менш чутливим до випадкових відхилень в даних, ніж LOOCV, оскільки використовується середнє значення точності на декількох комбінаціях тренувальних та тестових наборів даних.\n",
    "Проте k-fold cross-validation також має свої недоліки:\n",
    "\n",
    "Метод може бути неефективним для наборів даних з нерівномірним розподілом класів, оскільки під час поділу на тренувальний та тестовий набори даних може виникнути нерівномірне розподілення класів.\n",
    "Залежно від обраних параметрів k та способу розбиття набору даних на тренувальний та тестовий, k-fold cross-validation може давати різні результати, що може призвести до неточної оцінки ефективності моделі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc751d-f202-4f1b-ad0c-be36ab532c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
